var searchIndex = {};
searchIndex['json_tools'] = {"items":[[0,"","json_tools","For usage examples, please have a look at the *tests* and *benchmarks*.",null,null],[3,"Lexer","","A lexer for utf-8 encoded json data",null,null],[3,"Token","","A lexical token, identifying its kind and span.",null,null],[12,"kind","","The exact type of the token",0,null],[12,"buf","","A buffer representing the bytes of this Token.",0,null],[3,"Span","","A pair of indices into the byte stream returned by our source\niterator.\nIt is an exclusive range.",null,null],[12,"first","","Index of the first the byte",1,null],[12,"end","","Index one past the last byte",1,null],[3,"FilterTypedKeyValuePairs","","Removes tokens matching `,? \"key\": <type> ,?`., where `<type>` is a given\ntoken type. Useful for removing `null` values, or all numbers, for instance.\nIs made in a resilient fashion which doesn't require a sane input token stream.",null,null],[3,"TokenReader","","An adapter to convert a stream of `Token`s into bytes by implementing an\n`std::io::Read` trait.",null,null],[4,"TokenType","","",null,null],[13,"CurlyOpen","","`{`",2,null],[13,"CurlyClose","","`}`",2,null],[13,"BracketOpen","","`[`",2,null],[13,"BracketClose","","`]`",2,null],[13,"Colon","","`:`",2,null],[13,"Comma","","`,`",2,null],[13,"String","","A json string , like `\"foo\"`",2,null],[13,"BooleanTrue","","`true`",2,null],[13,"BooleanFalse","","`false`",2,null],[13,"Number","","A Number, like `1.1234` or `123` or `-0.0` or `-1` or `.0` or `.`",2,null],[13,"Null","","any json number, like `1.24123` or `123`\n`null`",2,null],[13,"Invalid","","The type of the token could not be identified.\nShould be removed if this lexer is ever to be feature complete",2,null],[4,"BufferType","","The type of `Buffer` you want in each `Token`",null,null],[13,"Bytes","","Use a `Buffer::MultiByte` were appropriate. Initialize it with the\ngiven capcity (to obtain higher performance when pushing charcters)",3,null],[13,"Span","","",3,null],[4,"Buffer","","Representation of a buffer containing items making up a `Token`.",null,null],[13,"MultiByte","","Multiple bytes making up a token. Only set for `TokenType::String` and\n`TokenType::Number`.",4,null],[13,"Span","","The span allows to reference back into the source byte stream\nto obtain the string making up the token.\nPlease note that for control characters, booleans and null (i.e\nanything that is not `Buffer::MultiByte` you should use \n`<TokenType as AsRef<str>>::as_ref()`)",4,null],[11,"clone","","",2,{"inputs":[{"name":"tokentype"}],"output":{"name":"tokentype"}}],[11,"eq","","",2,{"inputs":[{"name":"tokentype"},{"name":"tokentype"}],"output":{"name":"bool"}}],[11,"ne","","",2,{"inputs":[{"name":"tokentype"},{"name":"tokentype"}],"output":{"name":"bool"}}],[11,"fmt","","",2,{"inputs":[{"name":"tokentype"},{"name":"formatter"}],"output":{"name":"result"}}],[11,"as_ref","","",2,{"inputs":[{"name":"tokentype"}],"output":{"name":"str"}}],[11,"default","","",1,{"inputs":[{"name":"span"}],"output":{"name":"span"}}],[11,"clone","","",1,{"inputs":[{"name":"span"}],"output":{"name":"span"}}],[11,"eq","","",1,{"inputs":[{"name":"span"},{"name":"span"}],"output":{"name":"bool"}}],[11,"ne","","",1,{"inputs":[{"name":"span"},{"name":"span"}],"output":{"name":"bool"}}],[11,"fmt","","",1,{"inputs":[{"name":"span"},{"name":"formatter"}],"output":{"name":"result"}}],[11,"clone","","",0,{"inputs":[{"name":"token"}],"output":{"name":"token"}}],[11,"eq","","",0,{"inputs":[{"name":"token"},{"name":"token"}],"output":{"name":"bool"}}],[11,"ne","","",0,{"inputs":[{"name":"token"},{"name":"token"}],"output":{"name":"bool"}}],[11,"fmt","","",0,{"inputs":[{"name":"token"},{"name":"formatter"}],"output":{"name":"result"}}],[11,"clone","","",4,{"inputs":[{"name":"buffer"}],"output":{"name":"buffer"}}],[11,"eq","","",4,{"inputs":[{"name":"buffer"},{"name":"buffer"}],"output":{"name":"bool"}}],[11,"ne","","",4,{"inputs":[{"name":"buffer"},{"name":"buffer"}],"output":{"name":"bool"}}],[11,"fmt","","",4,{"inputs":[{"name":"buffer"},{"name":"formatter"}],"output":{"name":"result"}}],[11,"clone","","",3,{"inputs":[{"name":"buffertype"}],"output":{"name":"buffertype"}}],[11,"eq","","",3,{"inputs":[{"name":"buffertype"},{"name":"buffertype"}],"output":{"name":"bool"}}],[11,"ne","","",3,{"inputs":[{"name":"buffertype"},{"name":"buffertype"}],"output":{"name":"bool"}}],[11,"fmt","","",3,{"inputs":[{"name":"buffertype"},{"name":"formatter"}],"output":{"name":"result"}}],[11,"new","","Returns a new Lexer from a given byte iterator.",5,{"inputs":[{"name":"lexer"},{"name":"i"},{"name":"buffertype"}],"output":{"name":"lexer"}}],[11,"into_inner","","",5,{"inputs":[{"name":"lexer"}],"output":{"name":"intoiter"}}],[11,"next","","Lex the underlying bytte stream to generate tokens",5,{"inputs":[{"name":"lexer"}],"output":{"name":"option"}}],[11,"new","","Returns a new `FilterTypedKeyValuePairs` instance from a `Token` iterator",6,{"inputs":[{"name":"filtertypedkeyvaluepairs"},{"name":"i"},{"name":"tokentype"}],"output":{"name":"filtertypedkeyvaluepairs"}}],[11,"next","","",6,{"inputs":[{"name":"filtertypedkeyvaluepairs"}],"output":{"name":"option"}}],[11,"new","","Returns a new `TokenReader`\n# Args\n* `iter` - the iterator producing `Token` instances we are to convert\n* `source` - an optional, original string from which the tokens were\n             generated. This offers the best performance when\n             serializing tokens, as they can refer to their original\n             `&str` slice.",7,{"inputs":[{"name":"tokenreader"},{"name":"i"},{"name":"option"}],"output":{"name":"tokenreader"}}],[11,"read","","",7,null],[8,"IteratorExt","","Applies convenience constructors to all `Iterator<Item=Token>` types",null,null],[11,"filter_key_value_by_type","","Returns an Iterator which filters key=value pairs, if `value.kind` matches\nthe given `token_type`.",8,{"inputs":[{"name":"iteratorext"},{"name":"tokentype"}],"output":{"name":"filtertypedkeyvaluepairs"}}],[11,"reader","","Returns a `TokenReader` to produce a byte stream from `Token` instances",8,{"inputs":[{"name":"iteratorext"},{"name":"option"}],"output":{"name":"tokenreader"}}],[11,"filter_key_value_by_type","","Returns an Iterator which filters key=value pairs, if `value.kind` matches\nthe given `token_type`.",8,{"inputs":[{"name":"iteratorext"},{"name":"tokentype"}],"output":{"name":"filtertypedkeyvaluepairs"}}],[11,"reader","","Returns a `TokenReader` to produce a byte stream from `Token` instances",8,{"inputs":[{"name":"iteratorext"},{"name":"option"}],"output":{"name":"tokenreader"}}]],"paths":[[3,"Token"],[3,"Span"],[4,"TokenType"],[4,"BufferType"],[4,"Buffer"],[3,"Lexer"],[3,"FilterTypedKeyValuePairs"],[3,"TokenReader"],[8,"IteratorExt"]]};
initSearch(searchIndex);
